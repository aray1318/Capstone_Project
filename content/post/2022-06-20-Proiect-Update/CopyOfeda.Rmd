---
title: "pga_tour"
author: "Andrew Raymond"
date: "6/6/2022"
output: html_document
---

## Loading the data

```{r}
library(tidyverse)
pga_data = read_csv("CopyOfpga_tour.csv")


pga_data = pga_data %>%
  select(-`Unnamed: 2`, -`Unnamed: 3`, -`Unnamed: 4`)


pga_data
```

## Tour Championship Data 

Here I filtered out the tournament the "Tour Championship" from the main data frame. Then I only selected the winners so I could gain some insight about what their average metrics. The metrics that were the most important for winning the tournament were strokes gained total, strokes gained tee to green, and strokes gained off the tee.

```{r}
tour_championship <- pga_data[pga_data$`tournament name` == "Tour Championship",]
view(tour_championship)

tour_championship =tour_championship %>% 
  group_by(season) %>% 
  slice(which.min(pos))%>%
  select(-hole_DKP, - hole_FDP, - hole_SDP, -streak_DKP, -streak_FDP, - streak_SDP, -finish_DKP, - finish_SDP, -total_DKP, -total_FDP, -total_SDP, -finish_FDP, -total_FDP)

drop_na(tour_championship[,17:22])%>%
  summarise_all(function(x)mean(x))
```


## BMW Championship Data 

Here I filtered out the tournament the "BMW Championship" from the main data frame. Then I only selected the winners so I could gain some insight about what their average metrics. The metrics that were the most important for winning the tournament were strokes gained total, strokes gained tee to green, and strokes gained putting.

```{r}
bmw_championship <- pga_data[pga_data$`tournament name` == "BMW Championship",]


bmw_championship = bmw_championship %>%
  group_by(season) %>% 
  slice(which.min(pos)) %>%
  select(-hole_DKP, - hole_FDP, - hole_SDP, -streak_DKP, -streak_FDP, - streak_SDP, -finish_DKP, - finish_SDP, -total_DKP, -total_FDP, -total_SDP, -finish_FDP, -total_FDP)

drop_na(bmw_championship[,17:22])%>%
  summarise_all(function(x)mean(x))

bmw_championship[7]
```
Logistic Regression for BMW

```{r}
bmw <- pga_data[pga_data$`tournament name` == "BMW Championship",]
head(bmw_championship)

bmw[bmw$player == "Bryson DeChambeau",]

bmw_model = bmw %>%
  select(-Player_initial_last, -`tournament id`, - `player id`, - hole_par, -strokes, -n_rounds, -player, -`tournament name`, -course, -date, -purse, -no_cut, -Finish, -hole_DKP, -hole_FDP, -hole_SDP, -streak_DKP, -streak_FDP, -streak_SDP, -finish_DKP, -finish_FDP, -finish_SDP, -season, -total_DKP, -total_FDP, -total_SDP)
na.omit(bmw_model)

bmw_model$Top_25 <- as.numeric(bmw_model$pos >= 25)
bmw_model$Top_10 <- as.numeric(bmw_model$pos >= 10)

bmw_model = bmw_model%>%
  select(-made_cut, -pos, -sg_total)
bmw_model

```
Model for Top 25

```{r}
library(caret)
library(naivebayes)

bmw_model1 = na.omit(bmw_model)%>%
  select(-Top_10)

set.seed(504)
bmw_index <- createDataPartition(bmw_model1$Top_25, p = 0.8, list = FALSE)
train <- bmw_model1[ bmw_index, ]
test <- bmw_model1[-bmw_index, ]
table(train$Top_25)


control <- trainControl(method = "cv", number = 5)
fit <- train(Top_25 ~ .,
             data = train, 
             trControl = control,
             method = "glm",
             family = "binomial")

prob <- predict(fit, newdata=test)

pred <- ifelse(prob > 0.5, 1, 0)

confusionMatrix(factor(pred),factor(test$Top_25))


plot(varImp(fit, scale= TRUE))


```
Model for Top 10

```{r}
bmw_model2 = na.omit(bmw_model)%>%
  select(-Top_25)

set.seed(504)
bmw_index <- createDataPartition(bmw_model2$Top_10, p = 0.8, list = FALSE)
train <- bmw_model2[ bmw_index, ]
test <- bmw_model2[-bmw_index, ]
table(train$Top_10)


control <- trainControl(method = "cv", number = 5)
fit <- train(Top_10 ~ .,
             data = train, 
             trControl = control,
             method = "glm",
             family = "binomial")

prob <- predict(fit, newdata=test)

pred <- ifelse(prob > 0.5, 1, 0)

confusionMatrix(factor(pred),factor(test$Top_10))


plot(varImp(fit, scale= TRUE))


```

## Northern Trust Data 

Here I filtered out the tournament the "Northern Trust" from the main data frame. Then I only selected the winners so I could gain some insight about what their average metrics. The metrics that were the most important for winning the tournament were strokes gained total, strokes gained tee to green, and strokes gained approach.

```{r}
north_trust <- pga_data[pga_data$`tournament name` %in% c("Northern Trust Open", "The Northern Trust"),]
drop_na(north_trust) 
#view(north_trust)
north_trust = north_trust%>% 
  group_by(season) %>% 
  slice(which.min(Finish)) %>% 
  filter(season > 2016)%>%
  select(-hole_DKP, - hole_FDP, - hole_SDP, -streak_DKP, -streak_FDP, - streak_SDP, -finish_DKP, - finish_SDP, -total_DKP, -total_FDP, -total_SDP, -finish_FDP, -total_FDP)

drop_na(north_trust[,17:22])%>%
  summarise_all(function(x)mean(x))
```

North Trust Logistic Regression Model

```{r}
north <- pga_data[pga_data$`tournament name` %in% c("Northern Trust Open", "The Northern Trust"),]

north_model = north %>%
  select(-Player_initial_last, -`tournament id`, - `player id`, - hole_par, -strokes, -n_rounds, -player, -`tournament name`, -course, -date, -purse, -no_cut, -Finish, -hole_DKP, -hole_FDP, -hole_SDP, -streak_DKP, -streak_FDP, -streak_SDP, -finish_DKP, -finish_FDP, -finish_SDP, -season, -total_DKP, -total_FDP, -total_SDP)
north_model = na.omit(north_model)
north_model

north_model$Top_25 <- as.numeric(north_model$pos >= 25)
north_model$Top_10 <- as.numeric(north_model$pos >= 10)

north_model = north_model%>%
  select(-made_cut, -pos)
north_model
```

Top 25

```{r}
north_model1 = na.omit(north_model)%>%
  select(-Top_10, -sg_total)

set.seed(504)
north_index <- createDataPartition(north_model1$Top_25, p = 0.5, list = FALSE)
train <- north_model1[ north_index, ]
test <- north_model1[-north_index, ]
table(train$Top_25)


control <- trainControl(method = "cv", number = 5)
fit <- train(Top_25 ~ .,
             data = train, 
             trControl = control,
             method = "glm",
             family = "binomial")

prob <- predict(fit, newdata=test)

pred <- ifelse(prob > 0.5, 1, 0)

confusionMatrix(factor(pred),factor(test$Top_25))


plot(varImp(fit, scale= TRUE))

```

Top 10

```{r}
north_model2 = na.omit(north_model)%>%
  select(-Top_25,- sg_total)

set.seed(504)
north_index <- createDataPartition(north_model2$Top_10, p = 0.5, list = FALSE)
train <- north_model2[ north_index, ]
test <- north_model2[-north_index, ]
table(train$Top_10)


control <- trainControl(method = "cv", number = 5)
fit <- train(Top_10 ~ .,
             data = train, 
             trControl = control,
             method = "glm",
             family = "binomial")

prob <- predict(fit, newdata=test)

pred <- ifelse(prob > 0.5, 1, 0)

confusionMatrix(factor(pred),factor(test$Top_10))


plot(varImp(fit, scale= TRUE))

table(train$Top_10)


```


## Additional Data for Results by Season

```{r}
pga2 = read_csv("./CopyOfpgaTourData2.csv")
head(pga2)

#looking at distubution of data by year
ggplot(data = pga2, aes (x= Year))+
  geom_bar()

```

## Player's With Most Fedex Points by Season

I filtered out players who had the most Fedex Cup points in the data frame for each year. The metrics that were rated the highest for season long success were strokes gained total, strokes gained approach. 

```{r}
library(dplyr)

pga2 %>% 
  group_by(Year) %>% 
  slice(which.max(Points))

```


##Variable importance for predicting if a player wins in a given season

Here I created a basic model for determining if a player will win a tournament in a given season. The most significant indicators that were correlated with winning were points (which is fairly obvious because points are determined by how well you place in a tournament). Average score and number of top tens were also highly correlated (top tens essentially mean that a player has put themselves in more opportunities to win). Then lastly we had strokes gained total, strokes gained off the tee and scrambling (amount of times a player makes par or better when missing the fairway/green).

```{r}
library(caret)

pga3 = pga2
pga3
pga3$Wins = ifelse(is.na(pga3$Wins),0,1)

#head(pga3)

pga3 = drop_na(pga3)
```

colnames(pga3) <- make.names(colnames(pga3))

set.seed(504)

pga3$Wins = as.factor(pga3$Wins)

rPartMod <- train(Wins ~ ., data=pga3, method="rpart")

rpartImp <- varImp(rPartMod)

print(rpartImp)



## Distribution of Number of Players With and Without Wins

This chart shows the distribution of the number of players who did not win a tournament (0) and did win (1) by season. The main takeaway from this was that the seasons 2010, 2017, and 2018 had the least amount of variance. Meaning in this context that a smaller amount of players won and these players are more likely to win multiple times in these seasons.

```{r}
ggplot(data = pga3, aes (x= Wins))+
  geom_bar()+
  facet_wrap(~Year)+
  coord_flip()+
  ggtitle("Distribution of players that had 0 or 1+ wins on the PGA Tour by year")

```
-add interactions in models
-merge data frames on player name
-sg putting and winnings
-interactions between driving and putting




```{r}

pga3 = pga3 %>% 
  rename(player = `Player Name`)
head(pga3)

bmw = bmw %>% 
  rename(Year = season)

head(bmw)

library(dplyr)
BMW_Final = merge(bmw, pga3, by= c("player", "Year"))

BMW_Final[BMW_Final$player == "Bryson DeChambeau", ]

BMW_Final = BMW_Final%>%
  select(-Player_initial_last, -`tournament id`, - `player id`, - hole_par, -strokes, -n_rounds, -`tournament name`, -course, -date, -purse, -no_cut, -Finish, -hole_DKP, -hole_FDP, -hole_SDP, -streak_DKP, -streak_FDP, -streak_SDP, -finish_DKP, -finish_FDP, -finish_SDP, -total_DKP, -total_FDP, -total_SDP)

BMW_Final = BMW_Final%>%
  select(-made_cut, sg_putt, -sg_arg, -sg_app, -sg_ott, -sg_t2g, -sg_total, -Rounds, -Points, -Wins, -`Top 10`, -Money)

BMW_Final$Top_25 <- as.numeric(BMW_Final$pos >= 25)
BMW_Final$Top_10 <- as.numeric(BMW_Final$pos >= 10)

#BMW_Final = BMW_Final%>%
 # select(-pos)

BMW_Final = na.omit(BMW_Final)


```


```{r}
BMW_Final_25 = na.omit(BMW_Final)%>%
  select(-Top_10, -player, -Year, -gir, -pos)

head(BMW_Final_25)

BMW_Final_25 = na.omit(BMW_Final)%>%
  select(-sg_putt, -player, -pos, -Top_10, -Year)
  

head(BMW_Final_25)

set.seed(504)
BMW_F25_index <- createDataPartition(BMW_Final_25$Top_25, p = 0.5, list = FALSE)
train <- BMW_Final_25[ BMW_F25_index, ]
test <- BMW_Final_25[-BMW_F25_index, ]

table(train$Top_25)


control <- trainControl(method = "cv", number = 5)
fit <- train(Top_25 ~ .,
             data = train, 
             trControl = control,
             method = "glm",
             family = "binomial")

prob <- predict(fit, newdata=test)

pred <- ifelse(prob > 0.5, 1, 0)

confusionMatrix(factor(pred),factor(test$Top_25))


plot(varImp(fit, scale= TRUE))

```

top 10 bmw

```{r}
head(BMW_Final)

BMW_Final_10 = na.omit(BMW_Final)%>%
  select(-Top_25, -player, -Year, -gir, -pos)

head(BMW_Final_10)

#BMW_Final_10 = na.omit(BMW_Final)
  
BMW_Final_10 = BMW_Final_10%>%
  select(-`Average SG Total`, -sg_putt)

head(BMW_Final_10)
```


```{r}
set.seed(504)

head(BMW_Final_10)

BMW_F10_index <- createDataPartition(BMW_Final_10$Top_10, p = 0.5, list = FALSE)
train <- BMW_Final_10[ BMW_F10_index, ]
test <- BMW_Final_10[-BMW_F10_index, ]

table(train$Top_10)


control <- trainControl(method = "cv", number = 5)
fit <- train(Top_10 ~ .,
             data = train, 
             trControl = control,
             method = "glm",
             family = "binomial")

prob <- predict(fit, newdata=test)

pred <- ifelse(prob > 0.5, 1, 0)

confusionMatrix(factor(pred),factor(test$Top_10))


plot(varImp(fit, scale= TRUE))


```
North trust

```{r}

head(north)

north_model_F = north %>%
  select(-Player_initial_last, -`tournament id`, - `player id`, - hole_par, -strokes, -n_rounds, -`tournament name`, -course, -date, -purse, -no_cut, -Finish, -hole_DKP, -hole_FDP, -hole_SDP, -streak_DKP, -streak_FDP, -streak_SDP, -finish_DKP, -finish_FDP, -finish_SDP, -total_DKP, -total_FDP, -total_SDP)

#north_model_F = na.omit(north_model_F)

head(north_model_F)

north_model_F$Top_25 <- as.numeric(north_model_F$pos >= 25)
north_model_F$Top_10 <- as.numeric(north_model_F$pos >= 10)

north_model_F = north_model_F%>%
  select(-made_cut, -pos, -sg_putt, -sg_arg, -sg_app, -sg_ott, -sg_t2g, -sg_total)

head(north_model_F)

na.omit(north_model_F)

north_model_F= north_model_F%>%
  rename(Year = season)

head(north_model_F)

```



```{r}

North_Final = merge(north_model_F, pga3, by= c("player", "Year"))

North_Final[North_Final$player == "Bryson DeChambeau", ]

North_Final = na.omit(North_Final)

North_Final = North_Final%>%
  select(-Money, -`Top 10`, -Wins, -Points, -Year, -player)


```
 
North 25

```{r}
North_F25 = North_Final%>%
  select(-Top_10)

set.seed(504)

North_F25_index <- createDataPartition(North_F25$Top_25, p = 0.5, list = FALSE)
train <- North_F25[ North_F25_index, ]
test <- North_F25[-North_F25_index, ]

table(train$Top_25)


control <- trainControl(method = "cv", number = 5)
fit <- train(Top_25 ~ .,
             data = train, 
             trControl = control,
             method = "glm",
             family = "binomial")

prob <- predict(fit, newdata=test)

pred <- ifelse(prob > 0.5, 1, 0)

confusionMatrix(factor(pred),factor(test$Top_25))


plot(varImp(fit, scale= TRUE))


```


North Top 10

```{r}

North_F10 = North_Final%>%
  select(-Top_25)

set.seed(504)

North_F10_index <- createDataPartition(North_F10$Top_10, p = 0.2, list = FALSE)
train <- North_F10[ North_F10_index, ]
test <- North_F10[-North_F10_index, ]

table(train$Top_10)


control <- trainControl(method = "cv", number = 5)
fit <- train(Top_10 ~ .,
             data = train, 
             trControl = control,
             method = "glm",
             family = "binomial")

prob <- predict(fit, newdata=test)

pred <- ifelse(prob > 0.5, 1, 0)

confusionMatrix(factor(pred),factor(test$Top_10))


plot(varImp(fit, scale= TRUE))



```


-random forest models

-graph is top x finish and y axis is accuracy

-graph how predictive power decreases as finishes get better

-case study for best players for a given tournament 

